{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> Application of Support Vector Machine to Gene Expression Data (Khan.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0  c        V1        V2        V3        V4        V5        V6  \\\n",
      "0         V1  2  0.773344 -2.438405 -0.482562 -2.721135 -1.217058  0.827809   \n",
      "1         V2  2 -0.078178 -2.415754  0.412772 -2.825146 -0.626236  0.054488   \n",
      "2         V3  2 -0.084469 -1.649739 -0.241308 -2.875286 -0.889405 -0.027474   \n",
      "3         V4  2  0.965614 -2.380547  0.625297 -1.741256 -0.845366  0.949687   \n",
      "4         V5  2  0.075664 -1.728785  0.852626  0.272695 -1.841370  0.327936   \n",
      "\n",
      "         V7        V8  ...     V2299     V2300     V2301     V2302     V2303  \\\n",
      "0  1.342604  0.057042  ... -0.238511 -0.027474 -1.660205  0.588231 -0.463624   \n",
      "1  1.429498 -0.120249  ... -0.657394 -0.246284 -0.836325 -0.571284  0.034788   \n",
      "2  1.159300  0.015676  ... -0.696352  0.024985 -1.059872 -0.403767 -0.678653   \n",
      "3  1.093801  0.819736  ...  0.259746  0.357115 -1.893128  0.255107  0.163309   \n",
      "4  1.251219  0.771450  ... -0.200404  0.061753 -2.273998 -0.039365  0.368801   \n",
      "\n",
      "      V2304     V2305     V2306     V2307     V2308  \n",
      "0 -3.952845 -5.496768 -1.414282 -0.647600 -1.763172  \n",
      "1 -2.478130 -3.661264 -1.093923 -1.209320 -0.824395  \n",
      "2 -2.939352 -2.736450 -1.965399 -0.805868 -1.139434  \n",
      "3 -1.021929 -2.077843 -1.127629  0.331531 -2.179483  \n",
      "4 -2.566551 -1.675044 -1.082050 -0.965218 -1.836966  \n",
      "\n",
      "[5 rows x 2310 columns]\n",
      "(83, 2310)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# 83 tissue samples are classified into four cancer types based on 2308 gene expression measurements\n",
    "raw0 = pd.read_csv('Khan.csv') \n",
    "\n",
    "print(raw0.head())\n",
    "print(raw0.shape) # high-dimensional data (large # of features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Select a kernel function and tune the penalty parameter \"C\" using CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> i) Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw0.iloc[:,2:]\n",
    "Y = raw0.iloc[:,1]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # suppress warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random state - like random seed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> ii) Select a kernel function and tune the penalty parameter \"C\" using \"GridSearchCV\"\n",
    "* SVC: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "* Available kernel functions: https://scikit-learn.org/stable/modules/svm.html#svm-kernels\n",
    "* Precision & Recall: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.970 (+/-0.049) for {'C': 1, 'kernel': 'rbf'}\n",
      "1.000 (+/-0.000) for {'C': 10, 'kernel': 'rbf'}\n",
      "1.000 (+/-0.000) for {'C': 100, 'kernel': 'rbf'}\n",
      "1.000 (+/-0.000) for {'C': 1000, 'kernel': 'rbf'}\n",
      "1.000 (+/-0.000) for {'C': 1, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 10, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 100, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.883 (+/-0.226) for {'C': 1, 'degree': 5, 'kernel': 'poly'}\n",
      "0.522 (+/-0.475) for {'C': 1, 'degree': 10, 'kernel': 'poly'}\n",
      "0.494 (+/-0.441) for {'C': 1, 'degree': 15, 'kernel': 'poly'}\n",
      "0.865 (+/-0.218) for {'C': 10, 'degree': 5, 'kernel': 'poly'}\n",
      "0.610 (+/-0.284) for {'C': 10, 'degree': 10, 'kernel': 'poly'}\n",
      "0.557 (+/-0.248) for {'C': 10, 'degree': 15, 'kernel': 'poly'}\n",
      "0.865 (+/-0.218) for {'C': 100, 'degree': 5, 'kernel': 'poly'}\n",
      "0.622 (+/-0.347) for {'C': 100, 'degree': 10, 'kernel': 'poly'}\n",
      "0.465 (+/-0.456) for {'C': 100, 'degree': 15, 'kernel': 'poly'}\n",
      "0.865 (+/-0.218) for {'C': 1000, 'degree': 5, 'kernel': 'poly'}\n",
      "0.618 (+/-0.361) for {'C': 1000, 'degree': 10, 'kernel': 'poly'}\n",
      "0.499 (+/-0.319) for {'C': 1000, 'degree': 15, 'kernel': 'poly'}\n",
      "0.339 (+/-0.084) for {'C': 1, 'coef0': 0, 'kernel': 'sigmoid'}\n",
      "0.133 (+/-0.192) for {'C': 1, 'coef0': 1, 'kernel': 'sigmoid'}\n",
      "0.133 (+/-0.192) for {'C': 1, 'coef0': 2, 'kernel': 'sigmoid'}\n",
      "0.953 (+/-0.053) for {'C': 10, 'coef0': 0, 'kernel': 'sigmoid'}\n",
      "0.871 (+/-0.257) for {'C': 10, 'coef0': 1, 'kernel': 'sigmoid'}\n",
      "0.133 (+/-0.192) for {'C': 10, 'coef0': 2, 'kernel': 'sigmoid'}\n",
      "0.701 (+/-0.213) for {'C': 100, 'coef0': 0, 'kernel': 'sigmoid'}\n",
      "0.913 (+/-0.085) for {'C': 100, 'coef0': 1, 'kernel': 'sigmoid'}\n",
      "0.963 (+/-0.065) for {'C': 100, 'coef0': 2, 'kernel': 'sigmoid'}\n",
      "0.619 (+/-0.317) for {'C': 1000, 'coef0': 0, 'kernel': 'sigmoid'}\n",
      "0.654 (+/-0.271) for {'C': 1000, 'coef0': 1, 'kernel': 'sigmoid'}\n",
      "0.857 (+/-0.205) for {'C': 1000, 'coef0': 2, 'kernel': 'sigmoid'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The scores are computed on test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.67      0.80         3\n",
      "           2       0.82      1.00      0.90         9\n",
      "           3       1.00      0.86      0.92         7\n",
      "           4       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.92        25\n",
      "   macro avg       0.95      0.88      0.91        25\n",
      "weighted avg       0.93      0.92      0.92        25\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.933 (+/-0.113) for {'C': 1, 'kernel': 'rbf'}\n",
      "1.000 (+/-0.000) for {'C': 10, 'kernel': 'rbf'}\n",
      "1.000 (+/-0.000) for {'C': 100, 'kernel': 'rbf'}\n",
      "1.000 (+/-0.000) for {'C': 1000, 'kernel': 'rbf'}\n",
      "1.000 (+/-0.000) for {'C': 1, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 10, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 100, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.871 (+/-0.178) for {'C': 1, 'degree': 5, 'kernel': 'poly'}\n",
      "0.571 (+/-0.394) for {'C': 1, 'degree': 10, 'kernel': 'poly'}\n",
      "0.500 (+/-0.354) for {'C': 1, 'degree': 15, 'kernel': 'poly'}\n",
      "0.846 (+/-0.168) for {'C': 10, 'degree': 5, 'kernel': 'poly'}\n",
      "0.613 (+/-0.310) for {'C': 10, 'degree': 10, 'kernel': 'poly'}\n",
      "0.562 (+/-0.326) for {'C': 10, 'degree': 15, 'kernel': 'poly'}\n",
      "0.846 (+/-0.168) for {'C': 100, 'degree': 5, 'kernel': 'poly'}\n",
      "0.646 (+/-0.300) for {'C': 100, 'degree': 10, 'kernel': 'poly'}\n",
      "0.487 (+/-0.348) for {'C': 100, 'degree': 15, 'kernel': 'poly'}\n",
      "0.846 (+/-0.168) for {'C': 1000, 'degree': 5, 'kernel': 'poly'}\n",
      "0.646 (+/-0.300) for {'C': 1000, 'degree': 10, 'kernel': 'poly'}\n",
      "0.517 (+/-0.293) for {'C': 1000, 'degree': 15, 'kernel': 'poly'}\n",
      "0.463 (+/-0.100) for {'C': 1, 'coef0': 0, 'kernel': 'sigmoid'}\n",
      "0.263 (+/-0.050) for {'C': 1, 'coef0': 1, 'kernel': 'sigmoid'}\n",
      "0.263 (+/-0.050) for {'C': 1, 'coef0': 2, 'kernel': 'sigmoid'}\n",
      "0.946 (+/-0.057) for {'C': 10, 'coef0': 0, 'kernel': 'sigmoid'}\n",
      "0.838 (+/-0.150) for {'C': 10, 'coef0': 1, 'kernel': 'sigmoid'}\n",
      "0.263 (+/-0.050) for {'C': 10, 'coef0': 2, 'kernel': 'sigmoid'}\n",
      "0.708 (+/-0.195) for {'C': 100, 'coef0': 0, 'kernel': 'sigmoid'}\n",
      "0.896 (+/-0.070) for {'C': 100, 'coef0': 1, 'kernel': 'sigmoid'}\n",
      "0.929 (+/-0.133) for {'C': 100, 'coef0': 2, 'kernel': 'sigmoid'}\n",
      "0.642 (+/-0.172) for {'C': 1000, 'coef0': 0, 'kernel': 'sigmoid'}\n",
      "0.683 (+/-0.165) for {'C': 1000, 'coef0': 1, 'kernel': 'sigmoid'}\n",
      "0.871 (+/-0.138) for {'C': 1000, 'coef0': 2, 'kernel': 'sigmoid'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The scores are computed on test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.67      0.80         3\n",
      "           2       0.82      1.00      0.90         9\n",
      "           3       1.00      0.86      0.92         7\n",
      "           4       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.92        25\n",
      "   macro avg       0.95      0.88      0.91        25\n",
      "weighted avg       0.93      0.92      0.92        25\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC # support vector machines for classification (SVR is for regression)\n",
    "\n",
    "# Create a dictionary with several combinations - some parameters were not chosen to optimize\n",
    "# 32 total cases - fine tune when grid search has been found\n",
    "# C controls bias - variance trade-off\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['poly'], 'degree': [5, 10, 15], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['sigmoid'], 'coef0': [0, 1, 2], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "# In many cases, you can just use accuracy\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    #Optimize grid search, using five fold cross validation calculating precision for each section, specify micro or macro\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='%s_macro' % score).fit(X_train, y_train)\n",
    "\n",
    "    # Precision or recall need macro or micro specification\n",
    "    print(\"Best parameters set found on train set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on train set:\")\n",
    "    print()\n",
    "    \n",
    "    ## Precisions or recalls for each combination\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    \n",
    "    print(\"The scores are computed on test set.\")\n",
    "    print()\n",
    "    \n",
    "    # Uses optimized function and provides a confusion matrix\n",
    "    print(classification_report(y_test, clf.predict(X_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> Classification of Web Documents Using Naive Bayes\n",
    "* https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> i) Import raw data (texts and their categories)\n",
    "* 20 news group data : \n",
    "    - http://qwone.com/~jason/20Newsgroups/\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# fetch_20newsgroups is a function !\n",
    "\n",
    "categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space'] # the entire data contains 20 categories but we'll be using only those categories\n",
    "\n",
    "remove = ('headers', 'footers', 'quotes') # remove non-main text\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove, shuffle=True, random_state=42)\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories, remove=remove, shuffle=True, random_state=42)\n",
    "\n",
    "# extract Y and X from the datasets\n",
    "Y_train = data_train.target \n",
    "Y_test = data_test.target\n",
    "\n",
    "X_train = data_train.data \n",
    "X_test = data_test.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train) # integers (0-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how each category is indexed -  the order appears different\n",
    "data_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "[1 3 2 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0]) # text\n",
    "print(Y_train) # integers (0-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> ii) Covert texts (bags of words) to numerical vectors\n",
    "* TfidfVectorizer \n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
    "    \n",
    "* Alternatively,\n",
    "    - CountVectorizer: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\n",
    "    - HashingVectorizer: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer\n",
    "    \n",
    "* Stop words: https://scikit-learn.org/stable/modules/feature_extraction.html#stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 26576)\n",
      "(1353, 26576)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "Vectorizer=TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# 1st detemine set of words and then use set of words to vectorize the data\n",
    "# Same set of words in the training set used to vectorizer of the test set\n",
    "X_train = Vectorizer.fit_transform(X_train) \n",
    "X_test = Vectorizer.transform(X_test) \n",
    "\n",
    "# !!!Caution: Use \".fit_transform()\" for training data, but use \".transform()\" for testing data\n",
    "# This is to make sure the training and test sets have the same number of columns (features) \n",
    "# Here we are using the vectorizer trained for the training data to convert the testing data\n",
    "\n",
    "# check the size of X_train\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> iii) Run NB\n",
    "* https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7420546932742055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65       319\n",
      "           1       0.88      0.92      0.90       389\n",
      "           2       0.73      0.92      0.81       394\n",
      "           3       0.78      0.23      0.36       251\n",
      "\n",
      "    accuracy                           0.74      1353\n",
      "   macro avg       0.75      0.69      0.68      1353\n",
      "weighted avg       0.75      0.74      0.71      1353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB as NB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "NBres= NB(alpha=1).fit(X_train, Y_train) # alpha is a kind of a shrinkage parameter\n",
    "\n",
    "print(NBres.score(X_test, Y_test))\n",
    "print(classification_report(Y_test, NBres.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7634885439763488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.57      0.62       319\n",
      "           1       0.90      0.88      0.89       389\n",
      "           2       0.75      0.89      0.82       394\n",
      "           3       0.66      0.62      0.64       251\n",
      "\n",
      "    accuracy                           0.76      1353\n",
      "   macro avg       0.75      0.74      0.74      1353\n",
      "weighted avg       0.76      0.76      0.76      1353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run SVC on the same data - result for second topic is highest \n",
    "from sklearn.svm import SVC\n",
    "SVCres= SVC(kernel = 'linear', C = 10).fit(X_train, Y_train)\n",
    "\n",
    "print(SVCres.score(X_test, Y_test))\n",
    "print(classification_report(Y_test, SVCres.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkred'> HW7: Similarly to HW6-2, optimize SVC and NB on the newsgroups data\n",
    "\n",
    "* Select ten categories and import raw data under your categories. Follow the steps above to prepare datasets to run SVC and NB\n",
    "* Use the function \"GridSearchCV\" to optimize SVC and NB\n",
    "    - To optimize SVC, select a kernel function and tune \"C\" parameter\n",
    "    - To optimize NB, tune \"alpha\" parameter\n",
    "* Use both \"precision\" and \"recall\" to evaluate prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# fetch_20newsgroups is a function !\n",
    "\n",
    "categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "        'rec.autos',\n",
    "        'rec.motorcycles',\n",
    "        'rec.sport.baseball',\n",
    "        'rec.sport.hockey',\n",
    "        'talk.politics.guns',\n",
    "        'sci.med'] # the entire data contains 20 categories but we'll be using only those categories\n",
    "\n",
    "remove = ('headers', 'footers', 'quotes') # remove non-main text\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove, shuffle=True, random_state=42)\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories, remove=remove, shuffle=True, random_state=42)\n",
    "\n",
    "# extract Y and X from the datasets\n",
    "Y_train = data_train.target \n",
    "Y_test = data_test.target\n",
    "\n",
    "X_train = data_train.data \n",
    "X_test = data_test.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'talk.politics.guns',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5563, 48939)\n",
      "(3703, 48939)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "Vectorizer=TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# 1st detemine set of words and then use set of words to vectorize the data\n",
    "# Same set of words in the training set used to vectorizer of the test set\n",
    "X_train = Vectorizer.fit_transform(X_train) \n",
    "X_test = Vectorizer.transform(X_test) \n",
    "\n",
    "# !!!Caution: Use \".fit_transform()\" for training data, but use \".transform()\" for testing data\n",
    "# This is to make sure the training and test sets have the same number of columns (features) \n",
    "# Here we are using the vectorizer trained for the training data to convert the testing data\n",
    "\n",
    "# check the size of X_train\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.807 (+/-0.024) for {'C': 1, 'kernel': 'linear'}\n",
      "0.822 (+/-0.031) for {'C': 10, 'kernel': 'linear'}\n",
      "0.818 (+/-0.021) for {'C': 100, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The scores are computed on test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.56       319\n",
      "           1       0.90      0.82      0.86       389\n",
      "           2       0.38      0.90      0.54       396\n",
      "           3       0.82      0.70      0.76       398\n",
      "           4       0.81      0.77      0.79       397\n",
      "           5       0.93      0.76      0.84       399\n",
      "           6       0.89      0.69      0.77       396\n",
      "           7       0.86      0.70      0.77       394\n",
      "           8       0.81      0.63      0.71       364\n",
      "           9       0.59      0.48      0.53       251\n",
      "\n",
      "    accuracy                           0.71      3703\n",
      "   macro avg       0.76      0.70      0.71      3703\n",
      "weighted avg       0.77      0.71      0.72      3703\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.787 (+/-0.021) for {'C': 1, 'kernel': 'linear'}\n",
      "0.748 (+/-0.028) for {'C': 10, 'kernel': 'linear'}\n",
      "0.687 (+/-0.017) for {'C': 100, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The scores are computed on test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58       319\n",
      "           1       0.85      0.85      0.85       389\n",
      "           2       0.71      0.79      0.75       396\n",
      "           3       0.58      0.82      0.68       398\n",
      "           4       0.84      0.80      0.82       397\n",
      "           5       0.93      0.82      0.87       399\n",
      "           6       0.84      0.78      0.81       396\n",
      "           7       0.77      0.76      0.77       394\n",
      "           8       0.78      0.72      0.75       364\n",
      "           9       0.60      0.49      0.54       251\n",
      "\n",
      "    accuracy                           0.75      3703\n",
      "   macro avg       0.75      0.74      0.74      3703\n",
      "weighted avg       0.76      0.75      0.75      3703\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC # support vector machines for classification (SVR is for regression)\n",
    "\n",
    "# Create a dictionary with several combinations - some parameters were not chosen to optimize\n",
    "# C controls bias - variance trade-off\n",
    "\n",
    "tuned_parameters = {'kernel': ['linear'], 'C': [1, 10,100],}\n",
    "\n",
    "# In many cases, you can just use accuracy\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    #Optimize grid search, using five fold cross validation calculating precision for each section, specify micro or macro\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='%s_macro' % score).fit(X_train, Y_train)\n",
    "\n",
    "    # Precision or recall need macro or micro specification\n",
    "    print(\"Best parameters set found on train set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on train set:\")\n",
    "    print()\n",
    "    \n",
    "    ## Precisions or recalls for each combination\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    \n",
    "    print(\"The scores are computed on test set.\")\n",
    "    print()\n",
    "    \n",
    "    # Uses optimized function and provides a confusion matrix\n",
    "    print(classification_report(Y_test, clf.predict(X_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The best training set is at C = 1 for a linear kernal function. In terms of highest precision, the model is most precise for predicting hockey and has the highest recall for the automotive news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'alpha': 0.05}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.828 (+/-0.014) for {'alpha': 0.01}\n",
      "0.832 (+/-0.017) for {'alpha': 0.05}\n",
      "0.808 (+/-0.014) for {'alpha': 1}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The scores are computed on test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.63       319\n",
      "           1       0.89      0.90      0.89       389\n",
      "           2       0.82      0.79      0.80       396\n",
      "           3       0.83      0.79      0.81       398\n",
      "           4       0.92      0.83      0.87       397\n",
      "           5       0.71      0.94      0.81       399\n",
      "           6       0.90      0.82      0.86       396\n",
      "           7       0.83      0.82      0.83       394\n",
      "           8       0.70      0.82      0.76       364\n",
      "           9       0.62      0.41      0.49       251\n",
      "\n",
      "    accuracy                           0.79      3703\n",
      "   macro avg       0.78      0.77      0.77      3703\n",
      "weighted avg       0.79      0.79      0.79      3703\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'alpha': 0.01}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.821 (+/-0.017) for {'alpha': 0.01}\n",
      "0.817 (+/-0.019) for {'alpha': 0.05}\n",
      "0.770 (+/-0.012) for {'alpha': 1}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The scores are computed on test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.62       319\n",
      "           1       0.90      0.89      0.90       389\n",
      "           2       0.80      0.76      0.78       396\n",
      "           3       0.79      0.76      0.78       398\n",
      "           4       0.93      0.83      0.87       397\n",
      "           5       0.71      0.94      0.81       399\n",
      "           6       0.89      0.81      0.85       396\n",
      "           7       0.81      0.83      0.82       394\n",
      "           8       0.72      0.78      0.75       364\n",
      "           9       0.57      0.49      0.53       251\n",
      "\n",
      "    accuracy                           0.78      3703\n",
      "   macro avg       0.78      0.77      0.77      3703\n",
      "weighted avg       0.79      0.78      0.78      3703\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB as NB\n",
    "\n",
    "\n",
    "tuned_parameters = {'alpha':[.01,.05,1,],}\n",
    "\n",
    "# In many cases, you can just use accuracy\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    #Optimize grid search, using five fold cross validation calculating precision for each section, specify micro or macro\n",
    "    clf = GridSearchCV(NB(), tuned_parameters, cv=5, scoring='%s_macro' % score).fit(X_train, Y_train)\n",
    "\n",
    "    # Precision or recall need macro or micro specification\n",
    "    print(\"Best parameters set found on train set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on train set:\")\n",
    "    print()\n",
    "    \n",
    "    ## Precisions or recalls for each combination\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    \n",
    "    print(\"The scores are computed on test set.\")\n",
    "    print()\n",
    "    \n",
    "    # Uses optimized function and provides a confusion matrix\n",
    "    print(classification_report(Y_test, clf.predict(X_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In terms of the training set for multinomial NB, the model has the highest precision for baseball new, and the highest recall for hockey news. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the SVC of 1, the highest model, the overall accuaracy is approximately .787 while the chosen model for Multinomial NB at .01 alpha has an accuracy of .821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
